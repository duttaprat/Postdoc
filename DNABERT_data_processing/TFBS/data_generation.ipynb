{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42cfb08d-6c54-41c3-99fa-05e01f7d170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d75c21-8648-47c3-be73-8a61766d2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2kmer(seq, k=6):\n",
    "    \"\"\"\n",
    "    Convert original sequence to kmers.\n",
    "    \n",
    "    Arguments:\n",
    "    seq -- str, original sequence.\n",
    "    k -- int, kmer of length k specified.\n",
    "    \n",
    "    Returns:\n",
    "    kmers -- str, kmers separated by space\n",
    "    \"\"\"\n",
    "    kmer = [seq[x:x+k] for x in range(len(seq)+1-k)]\n",
    "    kmers = \" \".join(kmer)\n",
    "    return kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b1acc1-3feb-40c2-8129-9b13e4ef4b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bed_file(file_path):\n",
    "    dataset = []\n",
    "    with open(file_path, 'r') as bed_file:\n",
    "        for line in bed_file:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) >= 6:  # Ensure the line has enough columns\n",
    "                sequence = parts[3]\n",
    "                label = parts[-1]\n",
    "                kmers = seq2kmer(sequence)\n",
    "                dataset.append((kmers, label))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c541e58-3a8c-4c84-8cc3-9715ae529918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_save(dataset, base_path, bed_file_name):\n",
    "    df = pd.DataFrame(dataset, columns=['Sequence', 'Label'])\n",
    "\n",
    "    # Split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['Sequence'], df['Label'], test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Prepare train and dev (test) DataFrames\n",
    "    train_df = pd.DataFrame({'Sequence': X_train, 'Label': y_train})\n",
    "    dev_df = pd.DataFrame({'Sequence': X_test, 'Label': y_test})\n",
    "    \n",
    "    # Create a directory named after the bed file\n",
    "    dir_path = os.path.join(base_path, bed_file_name.replace('.bed', ''))\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    \n",
    "    # Save the train and dev files\n",
    "    train_df.to_csv(os.path.join(dir_path, 'train.tsv'), sep='\\t', index=False)\n",
    "    dev_df.to_csv(os.path.join(dir_path, 'dev.tsv'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5204ceec-3441-4c59-8229-b97d81c48e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path= \"/data/projects/DNABERT_snv/Manuscript_11_2023/TFBS_fine_tune_data/Data_Jan_2024/1_1_pos_neg\"\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    # Skip .ipynb_checkpoints directories\n",
    "    if '.ipynb_checkpoints' in root:\n",
    "        continue\n",
    "    for file in files:\n",
    "        if file.endswith('.bed'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            dataset = process_bed_file(file_path)\n",
    "            split_and_save(dataset, root, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de10517a-a7a8-4c16-832d-7d5c01dba1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
